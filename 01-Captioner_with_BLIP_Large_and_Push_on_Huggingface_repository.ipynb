{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGgQmF2rO1DY"
      },
      "source": [
        "# Caption with BLIP Large\n",
        "You can find the latest update to the notebook [here](https://github.com/alexgenovese/generate-datasets-huggingface).\n",
        "\n",
        "\n",
        "[Image gif](https://cdn-uploads.huggingface.co/production/uploads/1670928184033-62441d1d9fdefb55a0b7d12c.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Env"
      ],
      "metadata": {
        "id": "fuG5gIhNIKWb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_IOte4F_aNLI"
      },
      "outputs": [],
      "source": [
        "#@title GDrive\n",
        "mount_drive = True #@param {type: 'boolean'}\n",
        "if mount_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ie6oPstv4Xx5"
      },
      "outputs": [],
      "source": [
        "#@title Install Dependencies\n",
        "#@markdown Installs requirements and imports CLIP data\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/dataset'):\n",
        "  !mkdir /content/dataset\n",
        "%cd /content\n",
        "!git clone https://github.com/theovercomer8/captionr\n",
        "%cd /content/captionr\n",
        "!pip install -r requirements.txt\n",
        "!apt-get install aria2\n",
        "!pip install prettytable\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "P8Zrmzbu5gEP"
      },
      "outputs": [],
      "source": [
        "#@title Login to Huggingface hub\n",
        "from huggingface_hub import login\n",
        "%store -r\n",
        "\n",
        "#@markdown Login to Huggingface hub\n",
        "#@markdown 1. You need a Huggingface account.\n",
        "#@markdown 2. To create a huggingface token, go to https://huggingface.co/settings/tokens, then create a new token or copy an available token with the `Write` role.\n",
        "write_token = \"\" #@param {type:\"string\"}\n",
        "login(write_token, add_to_git_credential=True)\n",
        "\n",
        "%store write_token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Do6uhfD85t91"
      },
      "outputs": [],
      "source": [
        "#@title Download and Extract Zip (.zip)\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "%store -r\n",
        "\n",
        "root_dir = '/content'\n",
        "#@markdown ### Define Zipfile URL or Zipfile Path\n",
        "zipfile_url_or_path = \"\" #@param {'type': 'string'}\n",
        "zipfile_dst = str(root_dir)+\"/zip_file.zip\"\n",
        "extract_to = \"/content/dataset\" #@param {'type': 'string'}\n",
        "\n",
        "if extract_to != \"\":\n",
        "  os.makedirs(extract_to, exist_ok=True)\n",
        "else:\n",
        "  extract_to = \"/content/dataset\"\n",
        "\n",
        "#@markdown This will ignore `extract_to` path and automatically extracting to `train_data_dir`\n",
        "is_dataset = False\n",
        "\n",
        "#@markdown Tick this if you want to extract all files directly to `extract_to` folder, and automatically delete the zip to save disk space\n",
        "auto_unzip_and_delete = False #@param{'type':'boolean'}\n",
        "\n",
        "dirname = os.path.dirname(zipfile_dst)\n",
        "basename = os.path.basename(zipfile_dst)\n",
        "\n",
        "try:\n",
        "  if zipfile_url_or_path.startswith(\"/content\"):\n",
        "    zipfile_dst = zipfile_url_or_path\n",
        "    if auto_unzip_and_delete == False:\n",
        "      if is_dataset:\n",
        "        extract_to = \"/content/dataset\"\n",
        "      !unzip -j {zipfile_dst} -d \"{extract_to}\"\n",
        "  elif zipfile_url_or_path.startswith(\"https://drive.google.com\"):\n",
        "    !gdown --fuzzy  {zipfile_url_or_path}\n",
        "  elif zipfile_url_or_path.startswith(\"magnet:?\"):\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 {zipfile_url_or_path}\n",
        "  elif zipfile_url_or_path.startswith(\"https://huggingface.co/\"):\n",
        "    if '/blob/' in zipfile_url_or_path:\n",
        "      zipfile_url_or_path = zipfile_url_or_path.replace('/blob/', '/resolve/')\n",
        "\n",
        "    hf_token = write_token\n",
        "    user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dirname} -o {basename} {zipfile_url_or_path}\n",
        "  else:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dirname} -o {basename} {zipfile_url_or_path}\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"An error occurred while downloading the file:\", e)\n",
        "\n",
        "if is_dataset:\n",
        "  extract_to = '/content/dataset'\n",
        "\n",
        "if auto_unzip_and_delete:\n",
        "  !unzip -j {zipfile_dst} -d \"{extract_to}\"\n",
        "\n",
        "  path_obj = Path(zipfile_dst)\n",
        "  zipfile_name = path_obj.parts[-1]\n",
        "\n",
        "  if os.path.isdir(zipfile_dst):\n",
        "    print(\"\\nThis zipfile doesn't exist or has been deleted \\n\")\n",
        "  else:\n",
        "    os.remove(zipfile_dst)\n",
        "    print(f\"\\n{zipfile_name} has been deleted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start"
      ],
      "metadata": {
        "id": "MAtf2v57ITcn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jt6lNJRa5aK6"
      },
      "outputs": [],
      "source": [
        "#@title Caption Wizard\n",
        "%cd /content/captionr\n",
        "\n",
        "from captionr.captionr_class import Captionr, CaptionrConfig\n",
        "from captionr.blip_cap import BLIP\n",
        "from captionr.blip2_cap import BLIP2\n",
        "from captionr.clip_interrogator import Interrogator, Config\n",
        "from captionr.coca_cap import Coca\n",
        "from captionr.git_cap import Git\n",
        "import os\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "from tqdm import tqdm\n",
        "from prettytable import PrettyTable\n",
        "from IPython.core.display import display, HTML\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "#@markdown Folder to scan for images\n",
        "folder_path = '/content/dataset' #@param {type:\"string\"}\n",
        "#@markdown Folder to output captions. Captions will be named the same as the input image with the chosen extension. Leave `output_path` blank to output captions side-by-side\n",
        "output_path = '' #@param {type:\"string\"}\n",
        "folder = [pathlib.Path(folder_path)]\n",
        "if output_path == '':\n",
        "  output = folder[0]\n",
        "else:\n",
        "  output = pathlib.Path(output_path)\n",
        "\n",
        "extension = 'txt' #@param ['txt','caption']\n",
        "#@markdown Action to take for existing caption files\n",
        "existing = 'ignore' #@param [ 'skip', 'ignore', 'copy', 'prepend', 'append']\n",
        "\n",
        "#@markdown Read caption from filename if caption file does not exist\n",
        "use_filename = False #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown Max caption length\n",
        "cap_length = 150 #@param {type: \"slider\", min: 0, max: 400}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "git = False #@param {type:\"boolean\"}\n",
        "coca = False #@param {type:\"boolean\"}\n",
        "blip = False #@param {type:\"boolean\"}\n",
        "#@markdown Will perform captioning in the priority set by `model_order` for any enabled models\n",
        "model_order = 'blip,git,coca' #@param ['coca,git,blip','coca,blip,git','git,coca,blip','git,blip,coca','blip,coca,git','blip,git,coca']\n",
        "#@markdown Phrases that will fail a caption pass and move to the fallback model.\n",
        "fail_phrases = 'a sign that says,writing that says,that says,with the word' #@param\n",
        "#@markdown ---\n",
        "#@markdown BLIP options (if BLIP enabled)\n",
        "use_blip2 = True #@param {type:\"boolean\"}\n",
        "#@markdown BLIP2 requires the Pro tier High-RAM shape to run. Any of the xl or larger models require a premium GPU.\n",
        "blip2_model = 'Salesforce/blip-image-captioning-large' #@param ['Salesforce/blip-image-captioning-large', 'blip2_t5/pretrain_flant5xxl','blip2_opt/pretrain_opt2.7b', 'blip2_opt/pretrain_opt6.7b', 'blip2_opt/caption_coco_opt2.7b', 'blip2_opt/caption_coco_opt6.7b', 'blip2_t5/pretrain_flant5xl', 'blip2_t5/caption_coco_flant5xl']\n",
        "#@markdown Pipe `|` delimeted list of questions to ask BLIP2 and add answers as tags\n",
        "blip2_questions = '' #@param {type: \"string\"}\n",
        "#@markdown ---\n",
        "blip_beams = 8 #@param {type: \"slider\", min: 1, max: 100}\n",
        "blip_min = 30 #@param {type: \"slider\", min: 5, max: 75}\n",
        "blip_max = 56 #@param {type: \"slider\", min: 5, max: 75}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "clip_model_name = 'ViT-H-14/laion2b_s32b_b79k' #@param ['ViT-L-14/openai',\"ViT-H-14/laion2b_s32b_b79k\"]\n",
        "\n",
        "#@markdown Use ViT-H for SD 2.x, ViT-L for SD 1.5\n",
        "#@markdown\n",
        "#@markdown Only used if one of the following flavor/artist/medium/movement/trending checkboxes are checked\n",
        "\n",
        "clip_use_flavor = True #@param {type:\"boolean\"}\n",
        "clip_max_flavors = 16 #@param {type: \"slider\", min: 1, max: 100}\n",
        "clip_use_artist = False #@param {type:\"boolean\"}\n",
        "clip_use_medium = False #@param {type:\"boolean\"}\n",
        "clip_use_movement = False #@param {type:\"boolean\"}\n",
        "clip_use_trending = False  #@param {type:\"boolean\"}\n",
        "#@markdown Clip method to use\n",
        "clip_method = 'interrogate_fast' #@param ['interrogate','interrogate_fast','interrogate_classic']\n",
        "#@markdown ---\n",
        "#@markdown Comma separated list of tags to ignore\n",
        "ignore_tags = '' #@param {type:\"string\"}\n",
        "#@markdown Find/replace in caption and tags.\n",
        "find = '' #@param {type:\"string\"}\n",
        "replace = '' #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown Tag the caption with the containing folder. Useful when using nested folder structure. Can tag up to `folder_tag_levels` deep\n",
        "folder_tag = False #@param {type:\"boolean\"}\n",
        "folder_tag_levels = 1 #@param {type: \"slider\", min: 1, max: 10}\n",
        "#@markdown Do not tag folders any deeper than this path. Overrides `folder_tag_levels` if `folder_tag_stop` is shallower\n",
        "folder_tag_stop = '' #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown Ensure tag uniqueness if checked\n",
        "uniquify_tags = True #@param {type:\"boolean\"}\n",
        "#@markdown Similarity % allowed. Tags exceeding this percentage will be filtered.\n",
        "fuzz_ratio = 60 #@param {type:\"slider\", min: 0, max: 100}\n",
        "#@markdown Text to prepend or append to the generated caption. Useful for adding a subject or style\n",
        "prepend_text = '' #@param {type:\"string\"}\n",
        "append_text = '' #@param {type:\"string\"}\n",
        "#@markdown Check `preview` to just perform a preview run without writing a caption file\n",
        "preview = False #@param {type:\"boolean\"}\n",
        "print_params = False #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "try:\n",
        "  config\n",
        "except NameError:\n",
        "  config = CaptionrConfig()\n",
        "\n",
        "try:\n",
        "  last_blip2_model\n",
        "except NameError:\n",
        "  last_blip2_model = ''\n",
        "\n",
        "config.folder = folder\n",
        "config.output = output\n",
        "config.existing = existing\n",
        "config.cap_length = cap_length\n",
        "config.git_pass = git\n",
        "config.coca_pass = coca\n",
        "config.blip_pass = blip\n",
        "config.model_order = model_order\n",
        "config.use_blip2 = use_blip2\n",
        "config.blip2_model = blip2_model\n",
        "config.blip2_questions = blip2_questions.split('|')\n",
        "config.blip_beams = blip_beams\n",
        "config.blip_min = blip_min\n",
        "config.blip_max = blip_max\n",
        "config.clip_model_name = clip_model_name\n",
        "config.clip_flavor = clip_use_flavor\n",
        "config.clip_artist = clip_use_artist\n",
        "config.clip_medium = clip_use_medium\n",
        "config.clip_movement = clip_use_movement\n",
        "config.clip_trending = clip_use_trending\n",
        "config.clip_method = clip_method\n",
        "config.fuzz_ratio = fuzz_ratio\n",
        "config.fail_phrases = fail_phrases\n",
        "config.ignore_tags = ignore_tags\n",
        "config.find = find\n",
        "config.replace = replace\n",
        "config.folder_tag = folder_tag\n",
        "config.folder_tag_levels = folder_tag_levels\n",
        "config.preview = preview\n",
        "config.use_filename = use_filename\n",
        "config.append_text = append_text\n",
        "config.prepend_text = prepend_text\n",
        "config.uniquify_tags = uniquify_tags\n",
        "config.device = 'cuda'\n",
        "config.extension = extension\n",
        "config.quiet = True\n",
        "config.base_path = '/content/captionr'\n",
        "\n",
        "\n",
        "\n",
        "debug_params = [\"folder\", \\\n",
        "                \"output\", \\\n",
        "                \"existing\", \\\n",
        "                \"cap_length\", \\\n",
        "                \"git_pass\", \\\n",
        "                \"coca_pass\", \\\n",
        "                \"blip_pass\", \\\n",
        "                \"model_order\", \\\n",
        "                \"use_blip2\", \\\n",
        "                \"blip2_model\", \\\n",
        "                \"blip2_questions\", \\\n",
        "                \"blip_beams\", \\\n",
        "                \"blip_min\", \\\n",
        "                \"blip_max\", \\\n",
        "                \"clip_model_name\", \\\n",
        "                \"clip_flavor\", \\\n",
        "                \"clip_artist\", \\\n",
        "                \"clip_medium\", \\\n",
        "                \"clip_medium\", \\\n",
        "                \"clip_movement\", \\\n",
        "                \"clip_trending\", \\\n",
        "                \"clip_method\", \\\n",
        "                \"fuzz_ratio\", \\\n",
        "                \"fail_phrases\", \\\n",
        "                \"ignore_tags\", \\\n",
        "                \"find\", \\\n",
        "                \"replace\", \\\n",
        "                \"folder_tag\", \\\n",
        "                \"folder_tag_levels\", \\\n",
        "                \"preview\", \\\n",
        "                \"use_filename\", \\\n",
        "                \"append_text\", \\\n",
        "                \"prepend_text\", \\\n",
        "                \"uniquify_tags\", \\\n",
        "                \"device\", \\\n",
        "                \"extension\", \\\n",
        "                \"quiet\", \\\n",
        "                \"debug\", \\\n",
        "                \"_git\", \\\n",
        "                \"_coca\", \\\n",
        "                \"_blip\", \\\n",
        "                \"_clip\", \\\n",
        "                \"base_path\"]\n",
        "if print_params:\n",
        "  table = PrettyTable()\n",
        "  table.field_names = [\"Hyperparameter\", \"Value\"]\n",
        "  for params in debug_params:\n",
        "      if params != \"\":\n",
        "          if getattr(config,params) == \"\":\n",
        "              value = \"False\"\n",
        "          else:\n",
        "              value = getattr(config,params)\n",
        "          table.add_row([params, value])\n",
        "  table.align = \"l\"\n",
        "  print(table)\n",
        "\n",
        "if folder_path == '':\n",
        "  print ('Folder is required')\n",
        "  exit()\n",
        "\n",
        "\n",
        "if not config.git_pass \\\n",
        "      and not config.blip_pass \\\n",
        "      and not config.coca_pass \\\n",
        "      and not config.clip_flavor \\\n",
        "      and not config.clip_artist \\\n",
        "      and not config.clip_medium \\\n",
        "      and not config.clip_movement \\\n",
        "      and not config.clip_trending:\n",
        "  if config.existing == 'skip' \\\n",
        "      and  ( \\\n",
        "          ( \\\n",
        "              config.find is not None and config.find != '' \\\n",
        "              and config.replace is not None and config.replace != '' \\\n",
        "          ) \\\n",
        "          or config.folder_tag \\\n",
        "          or ( \\\n",
        "              config.prepend_text is not None \\\n",
        "              and config.prepend_text != '' \\\n",
        "          ) \\\n",
        "          or ( \\\n",
        "              config.append_text is not None \\\n",
        "              and config.append_text != '' \\\n",
        "          ) \\\n",
        "      ):\n",
        "\n",
        "      print ('existing=skip cannot be used for find/replace, folder tagging, text prepending/appending unless a caption model is selected. To run a caption pass without a model selected, please choose a different option for existing caption.')\n",
        "      exit()\n",
        "  else:\n",
        "      if config.existing == 'skip' \\\n",
        "          and not ( \\\n",
        "              (config.find is not None and config.find != '' \\\n",
        "              and config.replace is not None and config.replace != '') \\\n",
        "              or config.folder_tag \\\n",
        "              or (config.prepend_text is not None \\\n",
        "                  and config.prepend_text != '') \\\n",
        "              or (config.append_text is not None \\\n",
        "                  and config.append_text != '') \\\n",
        "          ):\n",
        "\n",
        "          print ('No captioning flags specified. Select a model or use CLIP tagging or use find/replace or use folder tagging or use append/prepend text to initiate captioning ')\n",
        "          exit()\n",
        "\n",
        "if config.coca_pass and config._coca is None:\n",
        "    print(\"Loading Coca Model...\")\n",
        "    config._coca = Coca(config.device,max_length=config.cap_length)\n",
        "\n",
        "if config.git_pass and config._git is None:\n",
        "    print(\"Loading Git Model...\")\n",
        "    config._git = Git(config.device,max_length=config.cap_length)\n",
        "\n",
        "if config.blip_pass and (config._blip is None or (config.blip2_model != last_blip2_model and config.use_blip2)):\n",
        "    if config.use_blip2:\n",
        "      if config.blip2_model != last_blip2_model:\n",
        "        config._blip = None\n",
        "        gc.collect()\n",
        "\n",
        "        with torch.no_grad():\n",
        "          torch.cuda.empty_cache()\n",
        "      print(\"Loading BLIP2 Model...\")\n",
        "      config._blip = BLIP2(config.device,model_name=config.blip2_model,max_length=config.cap_length)\n",
        "    else:\n",
        "      print(\"Loading BLIP Model...\")\n",
        "      config._blip = BLIP(config.device,beams=config.blip_beams,blip_max=config.blip_max, blip_min=config.blip_min)\n",
        "\n",
        "if config._clip == None and (config.clip_artist or config.clip_flavor or config.clip_medium or config.clip_movement or config.clip_trending):\n",
        "    print(\"Loading Clip Model...\")\n",
        "    config._clip = Interrogator(Config(clip_model_name=config.clip_model_name,\n",
        "                                        captionr_config=config,\n",
        "                                        quiet=config.quiet,\n",
        "                                        data_path=os.path.join(config.base_path,'data'),\n",
        "                                        cache_path=os.path.join(config.base_path,'data')))\n",
        "last_blip2_model = config.blip2_model\n",
        "\n",
        "paths = []\n",
        "cptr = Captionr(config=config)\n",
        "for folder in config.folder:\n",
        "    for root, dirs, files in os.walk(folder.absolute(), topdown=False):\n",
        "        for name in files:\n",
        "            if os.path.splitext(os.path.split(name)[1])[1].upper() not in ['.JPEG','.JPG','.JPE', '.PNG']:\n",
        "                continue\n",
        "            if config.extension not in os.path.splitext(os.path.split(name)[1])[1]:\n",
        "                cap_file = os.path.join(folder.absolute(),os.path.splitext(os.path.split(name)[1])[0] + f'.{config.extension}')\n",
        "            if not config.existing == 'skip' or not os.path.exists(cap_file):\n",
        "                paths.append(os.path.join(root, name))\n",
        "            else:\n",
        "                print(f'Caption file {cap_file} exists. Skipping.')\n",
        "for path in tqdm(paths):\n",
        "    display(HTML(f'<div>-----</div><h1>{path}</h1>'))\n",
        "    with Image.open(path).convert('RGB') as img:\n",
        "      display(img.resize((200,200)))\n",
        "    caption = cptr.process_img(path)\n",
        "    display(HTML(f'<h2>Final Caption</h2><div>{caption}</div>'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HAaAtVBe_UJh"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "#@markdown #Edit Captions\n",
        "\n",
        "#@markdown - Open a tool to view/edit captions.\n",
        "\n",
        "paths=\"\"\n",
        "out=\"\"\n",
        "widgets_l=\"\"\n",
        "def Caption(path):\n",
        "    name = os.path.splitext(os.path.basename(path))[0]\n",
        "    ext=os.path.splitext(os.path.basename(path))[-1][1:]\n",
        "    if ext==\"jpg\" or \"JPG\":\n",
        "      ext=\"JPEG\"\n",
        "\n",
        "    if os.path.exists(folder_path+\"/\"+name + '.' + extension):\n",
        "      with open(folder_path+\"/\"+name + '.' + extension, 'r') as f:\n",
        "          text = f.read()\n",
        "    else:\n",
        "      with open(folder_path+\"/\"+name + '.' + extension, 'w') as f:\n",
        "          f.write(\"\")\n",
        "          with open(folder_path+\"/\"+name + '.' + extension, 'r') as f:\n",
        "              text = f.read()\n",
        "\n",
        "    img=Image.open(os.path.join(folder_path,path))\n",
        "    img=img.resize((420, 420))\n",
        "    image_bytes = BytesIO()\n",
        "    img.save(image_bytes, format=ext, qualiy=10)\n",
        "    image_bytes.seek(0)\n",
        "    image_data = image_bytes.read()\n",
        "    img= image_data\n",
        "    image = widgets.Image(\n",
        "        value=img,\n",
        "        width=420,\n",
        "        height=420\n",
        "    )\n",
        "    text_area = widgets.Textarea(value=text, description='', disabled=False, layout={'width': '300px', 'height': '120px'})\n",
        "\n",
        "\n",
        "    def update_text(text):\n",
        "        with open(folder_path+\"/\"+name + '.' + extension, 'w') as f:\n",
        "            f.write(text)\n",
        "\n",
        "    button = widgets.Button(description='Save', button_style='success')\n",
        "    button.on_click(lambda b: update_text(text_area.value))\n",
        "\n",
        "    return widgets.VBox([widgets.HBox([image, text_area, button])])\n",
        "\n",
        "\n",
        "paths = os.listdir(folder_path)\n",
        "paths = list(filter(lambda fn: not fn.endswith(extension), paths))\n",
        "\n",
        "widgets_l = widgets.Select(options=[\"Select an image to caption\"]+paths, rows=25)\n",
        "\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def click(change):\n",
        "    with out:\n",
        "        out.clear_output()\n",
        "        display(Caption(change.new))\n",
        "\n",
        "widgets_l.observe(click, names='value')\n",
        "display(widgets.HBox([widgets_l, out]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Huggingface settings to Push"
      ],
      "metadata": {
        "id": "EXfyZ0zUIZPZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F06v8KVh7m7j",
        "outputId": "79627b4e-fac1-4343-8d36-a85781784878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset repo: theovercomer8/to8highkey exists, skipping create repo\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Define your Huggingface Repo\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "%store -r\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "#@markdown #### If your model/dataset repo doesn't exist, it will automatically create your repo.\n",
        "dataset_name = \"\" #@param{type:\"string\"}\n",
        "make_this_dataset_private = True #@param{type:\"boolean\"}\n",
        "\n",
        "datasets_repo = user['name']+\"/\"+dataset_name.strip()\n",
        "\n",
        "if dataset_name != \"\":\n",
        "  try:\n",
        "      validate_repo_id(datasets_repo)\n",
        "      api.create_repo(repo_id=datasets_repo,\n",
        "                      repo_type=\"dataset\",\n",
        "                      private=make_this_dataset_private)\n",
        "      print(\"Dataset Repo didn't exists, creating repo\")\n",
        "      print(\"Dataset Repo\",datasets_repo,\"created!\\n\")\n",
        "\n",
        "  except HfHubHTTPError as e:\n",
        "      print(f\"Dataset repo: {datasets_repo} exists, skipping create repo\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dUKhs0SB60VE"
      },
      "outputs": [],
      "source": [
        "#@title Upload Dataset\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "#@markdown #### This will be compressed to zip and  uploaded to datasets repo, leave it empty if not necessary\n",
        "dataset_path = \"/content/dataset\" #@param {type :\"string\"}\n",
        "dataset_name = \"dataset\" #@param {type :\"string\"}\n",
        "#@markdown #### Delete zip after upload\n",
        "delete_zip = True #@param {type :\"boolean\"}\n",
        "\n",
        "tmp_dataset = \"/content/dataset\"\n",
        "\n",
        "dataset_zip = f\"/content/{dataset_name}.zip\"\n",
        "\n",
        "\n",
        "#@markdown #### Other Information\n",
        "commit_message = \"\" #@param {type :\"string\"}\n",
        "\n",
        "if not commit_message:\n",
        "  commit_message = \"feat: upload captioned dataset\"\n",
        "\n",
        "def upload_dataset(dataset_paths, is_zip : bool):\n",
        "  path_obj = Path(dataset_paths)\n",
        "  dataset_name = path_obj.parts[-1]\n",
        "\n",
        "  if is_zip:\n",
        "    print(f\"Uploading dataset to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=dataset_paths,\n",
        "        path_in_repo=dataset_name,\n",
        "        repo_id=datasets_repo,\n",
        "        repo_type=\"dataset\",\n",
        "        commit_message=commit_message,\n",
        "    )\n",
        "    print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/blob/main/\"+dataset_name+\"\\n\")\n",
        "  else:\n",
        "    print(f\"Uploading {dataset_name} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_folder(\n",
        "        folder_path=dataset_paths,\n",
        "        path_in_repo=dataset_name,\n",
        "        repo_id=datasets_repo,\n",
        "        repo_type=\"dataset\",\n",
        "        commit_message=commit_message,\n",
        "        ignore_patterns=\".ipynb_checkpoints\",\n",
        "    )\n",
        "    print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/tree/main/\"+dataset_name+\"\\n\")\n",
        "\n",
        "def zip_file(tmp,zip):\n",
        "    zipfiles = zip\n",
        "    with zipfile.ZipFile(zipfiles, 'w') as zip:\n",
        "      for tmp, dirs, files in os.walk(tmp):\n",
        "          for file in files:\n",
        "              zip.write(os.path.join(tmp, file))\n",
        "\n",
        "def upload():\n",
        "  zip_file(tmp_dataset,dataset_zip)\n",
        "  upload_dataset(dataset_zip, True)\n",
        "  if delete_zip:\n",
        "    os.remove(dataset_zip)\n",
        "\n",
        "upload()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "fuG5gIhNIKWb",
        "MAtf2v57ITcn"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}